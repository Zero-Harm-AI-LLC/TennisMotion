{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47f3abd1",
   "metadata": {},
   "source": [
    "# Getting Started\n",
    "**Make sure to clear the cell output before check into GitHub**\n",
    "## Setup environment\n",
    "If you don't have a .venv (Python 3.xx) Python kernel environment in the top right items of this window, then the first thing to do is setup the Python environment kernel:\n",
    "- Go to View->Command Palette->Python: Create Environment... and run this command\n",
    "- Select this Python kernel in top right of this window as your running environment\n",
    "\n",
    "## Inference\n",
    "For inference testing, we using pretrained YOLO model from Ultralytics. We need to do the following:\n",
    "- Pip install the ultralytics library into our environment\n",
    "- Select the model you want to use. This can be the latest v11 or older but smaller model like v5. There are many different models. For instance YOLOv5xu is an advanced version integrating an anchor-free, objectness-free split head for improved accuracy-speed trade-off, while YOLOv5x6u is a larger model with a focus on higher accuracy.\n",
    "- Run the predict function. See documentation for information on the parameters\n",
    "\n",
    "## Notes\n",
    "We use the tennis ball dataset on RoboFlow to fine tune our YOLO model. As you can see from the results there are no tennis ball detection, since the model was trained on data that do not have tennis balls.\n",
    "We don't use RoboFlow model because of its architecture of client-server, so we need to run a server on the cloud. Ultralytics, you can download the trained model and include in your application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aacd129",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ultralytics\n",
    "import shutil\n",
    "\n",
    "# This script uses the YOLOv5 model to perform object detection on a video file.\n",
    "from ultralytics import YOLO \n",
    "\n",
    "# Load the YOLOv5 model from Ultralytics\n",
    "# model = YOLO('yolov5nu')\n",
    "\n",
    "# Load the YOLOv5 nano model that we trained earlier\n",
    "# You can also use 'yolov5xu' for a larger model with more parameters\n",
    "# model = YOLO(\"../tennis_ball_train/models/yolov5nu/train/weights/best.pt\")  # Load the YOLOv5 nano model\n",
    "\n",
    "# Load the YOLOv8 model with allow for partial pretrained classe\n",
    "model = YOLO('yolov8n.pt')  # Load the YOLOv8 nano model\n",
    "\n",
    "# confidence threshold for detection, filter out low confidence detections\n",
    "# conf=0.2 is a good starting point, but you can adjust it based on your needs\n",
    "# save=True will save the output video with detections\n",
    "results = model.predict('input/input_video.mp4',conf=0.2, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38c05a6",
   "metadata": {},
   "source": [
    "## Interpret inference results\n",
    "The results are in array of inference result. The names of the object is in the result.name. Such as below 0 = person, ...etc:\n",
    "```\n",
    "Class names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
    "```\n",
    "As you can see there is no tennis ball as an object label.\n",
    "Since this model was trained with a large set of objects there are many labels. The bounding box for each object is in result.box such as:\n",
    "```\n",
    "xywh: tensor([[551.2131, 841.1858, 144.2126, 180.8654]])\n",
    "xywhn: tensor([[0.2871, 0.7789, 0.0751, 0.1675]])\n",
    "xyxy: tensor([[479.1068, 750.7531, 623.3194, 931.6185]])\n",
    "xyxyn: tensor([[0.2495, 0.6951, 0.3246, 0.8626]])\n",
    "```\n",
    "The bounding box we will use is **xyxy**, top left x, y and bottom right x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b7a3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Print out the results of the object detection. each frame is in each result array\n",
    "# Print out all the bounding boxes for the first frame\n",
    "print(\"Class names:\", results[0].names)\n",
    "print(\"Bounding boxes for the first frame:\")\n",
    "# print out the bounding boxes for all the detected objects in all the frames\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"Frame {i+1}:\")\n",
    "    for box in result.boxes:\n",
    "        print(box)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
