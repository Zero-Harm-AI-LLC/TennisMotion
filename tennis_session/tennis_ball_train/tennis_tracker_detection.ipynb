{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c505550b",
   "metadata": {},
   "source": [
    "# Getting Started\n",
    "**Make sure to clear the cell output before check into GitHub**\n",
    "## Setup environment\n",
    "If you don't have a .venv (Python 3.xx) Python kernel environment in the top right items of this window, then the first thing to do is setup the Python environment kernel:\n",
    "- Go to View->Command Palette->Python: Create Environment... and run this command\n",
    "- Select this Python kernel in top right of this window as your running environment\n",
    "\n",
    "## Get Dataset\n",
    "To training you need the dataset. The dataset for tennis ball can be found on Roboflow.\n",
    "On Roboflow you can search for tennis dataset here: https://universe.roboflow.com/search\n",
    "\n",
    "There are pretrained model with the dataset, so in some case if there is already a pretrained mdoel that is accurate enough for your use case, then you don't need to retrain the mdoel.]\n",
    "\n",
    "The dataset that is used in this project is: https://universe.roboflow.com/tennistracker-dogbm/tennis-tracker-duufq/dataset/20#\n",
    "\n",
    "We will use YOLO8 model, which is not the latest YOLO model, however it is small and efficient to turn on a mobile device. You can retain pretrained classes and add new specific classes by using a technique called partial fine-tuning or custom head training.\n",
    "\n",
    "- Create a Roboflow account and log in\n",
    "- Select \"Download dataset\" option\n",
    "- Select \"Show download code\" option and accept the terms of agreement, you might need to go back to previous step if this is the first time you accept the agreement\n",
    "- Copy the Jupyter code snipplet to below\n",
    "- Replace the api_key with your API key from Roboflow under \"Settings->API Keys\"\n",
    "\n",
    "Notes: When you run the first time, it might complained that you need a ipykernal environment as an error. Resolve the error by click on the Create Python Kernel environment. You can also go to View->Command Palette->Python: Create Environment..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e2d0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"wNKC4X8SBzsq9OEpxrLC\")\n",
    "project = rf.workspace(\"tennistracker-dogbm\").project(\"tennis-tracker-duufq\")\n",
    "version = project.version(20)\n",
    "dataset = version.download(\"yolov8\")\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89184aab",
   "metadata": {},
   "source": [
    "## Training\n",
    "We will training using YOLO model for object detection. YOLO is used since it is for object detection and tracking from frame to frame. \n",
    "\n",
    "The dataset has 3 directories:\n",
    "- train: this is the images used to train the model\n",
    "- test: this is the images used to test the model after training is done\n",
    "- valid: this is used during the training process to tune model hyperparameters and prevent overfitting\n",
    "\n",
    "## Start training process\n",
    "To train using Ultralytics API, which should be straight forward with the number of epochs and image size. This will probably not run on the laptop without Nvidia GPU.\n",
    "Doc on Yolov5 https://docs.ultralytics.com/models/yolov5/#performance-metrics\n",
    "\n",
    "There are many Yolo v8 models. The 2 opposite models are:\n",
    "- yolov8x.pt where 'x' is extra large parameters which is used for high accuracy\n",
    "- yolov8n.pt where 'n' is nano parametrs which is small and fast but lack accuracy. We will use this model since our use case is for the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a199c44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ultralytics\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLOv8 model\n",
    "model = YOLO(\"yolov8n.pt\")  # Load the YOLOv5 nano model\n",
    "print(\"data set location:\", dataset.location)\n",
    "# Train the model on the dataset\n",
    "model.train(data=dataset.location + \"/data.yaml\", epochs=100, imgsz=640)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2910887a",
   "metadata": {},
   "source": [
    "## Google Collab\n",
    "This will probably not run on the laptop, so you should transfer the code to Google Collab to run on a GPU:\n",
    "- Create and login account on Google Collab https://colab.research.google.com/\n",
    "- Upload this notebook by drag-n-drop the file into the File->Open notebook dialog\n",
    "- Change your runtime to T4 GPU under Runtime->Change runtime type\n",
    "- Run all the start the training and output should be like:\n",
    "```\n",
    "  Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
    "     12/100      14.5G      3.171      2.148     0.9224         30        640: 100%|██████████| 27/27 [00:35<00:00,  1.32s/it]\n",
    "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:02<00:00,  1.97it/s]                   all        100        101      0.548      0.297       0.23     0.0472\n",
    "\n",
    "```\n",
    "- After the run, the models need to be copied to your Google drive. The below code is only needed if you are running this in Google Collab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54dd479",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "!cp -r /content/runs/detect/train* /content/drive/MyDrive/my_models/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
