{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c505550b",
   "metadata": {},
   "source": [
    "# Getting Started\n",
    "**Make sure to clear the cell output before check into GitHub**\n",
    "## Setup environment\n",
    "If you don't have a .venv (Python 3.xx) Python kernel environment in the top right items of this window, then the first thing to do is setup the Python environment kernel:\n",
    "- Go to View->Command Palette->Python: Create Environment... and run this command\n",
    "- Select this Python kernel in top right of this window as your running environment\n",
    "\n",
    "## Get Dataset\n",
    "To training you need the dataset. The dataset for tennis ball can be found on Roboflow.\n",
    "On Roboflow you can search for tennis dataset here: https://universe.roboflow.com/search?q=tennis+ball+model+object+detection+model%3Ayolov8\n",
    "\n",
    "There are pretrained model with the dataset, so in some case if there is already a pretrained mdoel that is accurate enough for your use case, then you don't need to retrain the mdoel.]\n",
    "\n",
    "The dataset that is used in this project is: https://universe.roboflow.com/viren-dhanwani/tennis-ball-detection/dataset/6\n",
    "\n",
    "We will use YOLOv8 model, which is not the latest YOLO model, however it is small and efficient and with Ultralytics YOLO (v8), you can retain pretrained classes and add new specific classes by using a technique called partial fine-tuning or custom head training. The idea is to start from a pretrained model and train it to recognize both existing classes and your new ones — without forgetting the old ones (i.e., no catastrophic forgetting). Retain existing YOLO classes (like person, car, dog) from pretrained weights and add new custom class tennis_ball.\n",
    "\n",
    "- Create a Roboflow account and log in\n",
    "- Select \"Download dataset\" option\n",
    "- Select \"Show download code\" option and accept the terms of agreement, you might need to go back to previous step if this is the first time you accept the agreement\n",
    "- Copy the Jupyter code snipplet to below\n",
    "- Replace the api_key with your API key from Roboflow under \"Settings->API Keys\"\n",
    "\n",
    "Notes: When you run the first time, it might complained that you need a ipykernal environment as an error. Resolve the error by click on the Create Python Kernel environment. You can also go to View->Command Palette->Python: Create Environment..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e2d0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"wNKC4X8SBzsq9OEpxrLC\")\n",
    "# Downloading a YOLOv8 dataset for tennis ball detection\n",
    "project = rf.workspace(\"viren-dhanwani\").project(\"tennis-ball-detection\")\n",
    "version = project.version(6)\n",
    "dataset = version.download(\"yolov8\")\n",
    "\n",
    "# Downloading a COCO dataset limited to person class\n",
    "project2 = rf.workspace(\"shreks-swamp\").project(\"coco-dataset-limited--person-only\")\n",
    "version2 = project2.version(1)\n",
    "dataset2 = version2.download(\"yolov8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89184aab",
   "metadata": {},
   "source": [
    "## Training\n",
    "We will training using YOLO model for object detection. YOLO is used since it is for object detection and tracking from frame to frame. To start training we need to setup the dataset directory in the right structure as expected by the training code.\n",
    "\n",
    "The dataset has 3 directories:\n",
    "- train: this is the images used to train the model\n",
    "- test: this is the images used to test the model after training is done\n",
    "- valid: this is used during the training process to tune model hyperparameters and prevent overfitting\n",
    "\n",
    "Prepare Dataset with Extended Class List\n",
    "\n",
    "Your data.yaml should list all the classes:\n",
    "\n",
    "The original YOLOv8 classes (e.g., COCO has 80 classes) plus your custom new classes.\n",
    "Example data.yaml:\n",
    "```\n",
    "    path: /path/to/dataset\n",
    "    train: images/train\n",
    "    val: images/val\n",
    "\n",
    "    names:\n",
    "    0: person\n",
    "    1: car\n",
    "    2: dog\n",
    "    ...\n",
    "    80: tennis ball\n",
    "```\n",
    "Current classes from YOLOv8 trained with COCO dataset are:\n",
    "```\n",
    "Class names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
    "```\n",
    "The label files also will need to be updated with the tennis_ball class (80) to match the data.yaml.\n",
    "\n",
    "Now, we can train using Ultralytics API, which should be straight forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060fbd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pyyaml\n",
    "\n",
    "import os\n",
    "def replace_first_column_in_files(directory_path, new_value):\n",
    "    for filename in os.listdir(directory_path):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        \n",
    "        # Only process regular files\n",
    "        if os.path.isfile(file_path):\n",
    "            with open(file_path, 'r') as file:\n",
    "                lines = file.readlines()\n",
    "            \n",
    "            modified_lines = []\n",
    "            for line in lines:\n",
    "                parts = line.strip().split()\n",
    "                if parts:\n",
    "                    parts[0] = new_value\n",
    "                    modified_lines.append(' '.join(parts) + '\\n')\n",
    "                else:\n",
    "                    modified_lines.append('\\n')  # Keep empty lines\n",
    "\n",
    "            # Write back modified content\n",
    "            with open(file_path, 'w') as file:\n",
    "                file.writelines(modified_lines)\n",
    "\n",
    "import yaml\n",
    "\n",
    "# Class dictionary you want to add\n",
    "class_names = {\n",
    "    0: \"person\",\n",
    "    1: \"bicycle\",\n",
    "    2: \"car\",\n",
    "    3: \"motorcycle\",\n",
    "    4: \"airplane\",\n",
    "    5: \"bus\",\n",
    "    6: \"train\",\n",
    "    7: \"truck\",\n",
    "    8: \"boat\",\n",
    "    9: \"traffic light\",\n",
    "    10: \"fire hydrant\",\n",
    "    11: \"stop sign\",\n",
    "    12: \"parking meter\",\n",
    "    13: \"bench\",\n",
    "    14: \"bird\",\n",
    "    15: \"cat\",\n",
    "    16: \"dog\",\n",
    "    17: \"horse\",\n",
    "    18: \"sheep\",\n",
    "    19: \"cow\",\n",
    "    20: \"elephant\",\n",
    "    21: \"bear\",\n",
    "    22: \"zebra\",\n",
    "    23: \"giraffe\",\n",
    "    24: \"backpack\",\n",
    "    25: \"umbrella\",\n",
    "    26: \"handbag\",\n",
    "    27: \"tie\",\n",
    "    28: \"suitcase\",\n",
    "    29: \"frisbee\",\n",
    "    30: \"skis\",\n",
    "    31: \"snowboard\",\n",
    "    32: \"sports ball\",\n",
    "    33: \"kite\",\n",
    "    34: \"baseball bat\",\n",
    "    35: \"baseball glove\",\n",
    "    36: \"skateboard\",\n",
    "    37: \"surfboard\",\n",
    "    38: \"tennis racket\",\n",
    "    39: \"bottle\",\n",
    "    40: \"wine glass\",\n",
    "    41: \"cup\",\n",
    "    42: \"fork\",\n",
    "    43: \"knife\",\n",
    "    44: \"spoon\",\n",
    "    45: \"bowl\",\n",
    "    46: \"banana\",\n",
    "    47: \"apple\",\n",
    "    48: \"sandwich\",\n",
    "    49: \"orange\",\n",
    "    50: \"broccoli\",\n",
    "    51: \"carrot\",\n",
    "    52: \"hot dog\",\n",
    "    53: \"pizza\",\n",
    "    54: \"donut\",\n",
    "    55: \"cake\",\n",
    "    56: \"chair\",\n",
    "    57: \"couch\",\n",
    "    58: \"potted plant\",\n",
    "    59: \"bed\",\n",
    "    60: \"dining table\",\n",
    "    61: \"toilet\",\n",
    "    62: \"tv\",\n",
    "    63: \"laptop\",\n",
    "    64: \"mouse\",\n",
    "    65: \"remote\",\n",
    "    66: \"keyboard\",\n",
    "    67: \"cell phone\",\n",
    "    68: \"microwave\",\n",
    "    69: \"oven\",\n",
    "    70: \"toaster\",\n",
    "    71: \"sink\",\n",
    "    72: \"refrigerator\",\n",
    "    73: \"book\",\n",
    "    74: \"clock\",\n",
    "    75: \"vase\",\n",
    "    76: \"scissors\",\n",
    "    77: \"teddy bear\",\n",
    "    78: \"hair drier\",\n",
    "    79: \"toothbrush\",\n",
    "    80: \"tennis ball\"\n",
    "}\n",
    "\n",
    "# Path to your YAML file\n",
    "yaml_path = dataset.location + \"/data.yaml\"\n",
    "\n",
    "# Load the YAML file\n",
    "with open(yaml_path, 'r') as file:\n",
    "    data = yaml.safe_load(file)\n",
    "\n",
    "# add new field 'names' to the YAML data\n",
    "data['names'] = class_names\n",
    "# Update the 'nc' value\n",
    "data['nc'] = len(class_names)\n",
    "\n",
    "# Save the updated YAML file\n",
    "with open(yaml_path, 'w') as file:\n",
    "    yaml.dump(data, file)\n",
    "\n",
    "# Replace the first column in all label files with \"80\" which is the class id for tennis ball\n",
    "replace_first_column_in_files(dataset.location + \"/train/labels\", \"80\")\n",
    "replace_first_column_in_files(dataset.location + \"/valid/labels\", \"80\")\n",
    "replace_first_column_in_files(dataset.location + \"/test/labels\", \"80\")\n",
    "\n",
    "# combining the two datasets\n",
    "# copy the COCO dataset to the tennis ball dataset\n",
    "import shutil\n",
    "def move_files(source_dir, destination_dir):\n",
    "    os.makedirs(destination_dir, exist_ok=True)\n",
    "\n",
    "    for filename in os.listdir(source_dir):\n",
    "        src_path = os.path.join(source_dir, filename)\n",
    "        dst_path = os.path.join(destination_dir, filename)\n",
    "        if os.path.isfile(src_path):\n",
    "            shutil.move(src_path, dst_path)\n",
    "\n",
    "move_files(dataset2.location + \"/test/images\", dataset.location + \"/test/images\")\n",
    "move_files(dataset2.location + \"/test/labels\", dataset.location + \"/test/labels\")\n",
    "move_files(dataset2.location + \"/train/images\", dataset.location + \"/train/images\")\n",
    "move_files(dataset2.location + \"/train/labels\", dataset.location + \"/train/labels\")\n",
    "move_files(dataset2.location + \"/valid/images\", dataset.location + \"/valid/images\")\n",
    "move_files(dataset2.location + \"/valid/labels\", dataset.location + \"/valid/labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43103f98",
   "metadata": {},
   "source": [
    "## Start training process\n",
    "To train using Ultralytics API, which should be straight forward with the number of epochs and image size. This will probably not run on the laptop without Nvidia GPU.\n",
    "Doc on Yolov8 https://docs.ultralytics.com/models/yolov8/#performance-metrics\n",
    "\n",
    "There are many Yolo v8 models. The 2 opposite models are yolov8xu.pt and yolov8nu.pt.\n",
    "- yolov8x.pt where 'x' is extra large parameters which is used for high accuracy\n",
    "- yolov8n.pt where 'n' is nano parametrs which is small and fast but lack accuracy. We will use this model since our use case is for the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a199c44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ultralytics\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLOv8 model\n",
    "model = YOLO(\"yolov8n.pt\")  # Load the YOLOv8 nano model\n",
    "print(\"data set location:\", dataset.location)\n",
    "# Train the model on the dataset\n",
    "model.train(data=dataset.location + \"/data.yaml\", epochs=100, imgsz=640)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2910887a",
   "metadata": {},
   "source": [
    "## Google Collab\n",
    "This will probably not run on the laptop, so you should transfer the code to Google Collab to run on a GPU:\n",
    "- Create and login account on Google Collab https://colab.research.google.com/\n",
    "- Upload this notebook by drag-n-drop the file into the File->Open notebook dialog\n",
    "- Change your runtime to T4 GPU under Runtime->Change runtime type\n",
    "- Run all the start the training and output should be like:\n",
    "```\n",
    "    Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
    "      12/100      14.5G      3.171      2.148     0.9224         30        640: 100%|██████████| 27/27 [00:35<00:00,  1.32s/it]\n",
    "                  Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:02<00:00,  1.97it/s]                   all        100        101      0.548      0.297       0.23     0.0472\n",
    "```\n",
    "- After the run, the models need to be copied to your Google drive. The below code is only needed if you are running this in Google Collab\n",
    "- Make sure you create a folder \"my_models\" under \"My Drive\" of your Google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54dd479",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "!cp -r /content/runs/detect/train* /content/drive/MyDrive/my_models/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
