{"cells":[{"cell_type":"markdown","id":"1c6282a3","metadata":{"id":"1c6282a3"},"source":["# Getting Started\n","**Make sure to clear the cell output before check into GitHub**\n","## Setup environment\n","If you don't have a .venv (Python 3.9) Python kernel environment in the top right items of this window, then the first thing to do is setup the Python environment kernel:\n","- Go to View->Command Palette->Python: Create Environment... and run this command\n","- Select this Python kernel in top right of this window as your running environment\n","\n","## Get the dataset\n","For keypoints detection of the tennis court, we will need the dataset of tennis court and labels of the keypoints."]},{"cell_type":"code","execution_count":null,"id":"3ae2304d","metadata":{"id":"3ae2304d"},"outputs":[],"source":["!wget --header=\"Host: drive.usercontent.google.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7\" --header=\"Accept-Language: en-US,en;q=0.9,ar;q=0.8\" --header=\"Cookie: HSID=Ag2OIHvsd2Wub4C7z; SSID=AWnBcQKwDHiTrZAU1; APISID=pltrFZgE9lJ0o1gq/AN9feEHYvs8oHd519; SAPISID=zgF45F21ZPWzYWZw/AgUMJ8b7QQXuWGn19; __Secure-1PAPISID=zgF45F21ZPWzYWZw/AgUMJ8b7QQXuWGn19; __Secure-3PAPISID=zgF45F21ZPWzYWZw/AgUMJ8b7QQXuWGn19; SID=g.a000fwgYx1PcnW-rFyFhg3x6mQHzCrwXz-KFhoOLogUl7YTWI-uttBbVDRolhF-hY16nwHXw0gACgYKAWISAQASFQHGX2MivNTw_E_toJuIRy6LMpKNOBoVAUF8yKpFSmvq7AMjvEWeNc50Zff40076; __Secure-1PSID=g.a000fwgYx1PcnW-rFyFhg3x6mQHzCrwXz-KFhoOLogUl7YTWI-utbSY2jBY1VXuw8gYl5hIO2QACgYKAXsSAQASFQHGX2MihVCJ1PwLozGqZgdSatM9QhoVAUF8yKpgrsTvI8i_UE-YHpoN7Gx-0076; __Secure-3PSID=g.a000fwgYx1PcnW-rFyFhg3x6mQHzCrwXz-KFhoOLogUl7YTWI-utwVfPl2imdPimZJ9tdDZGQAACgYKAUESAQASFQHGX2MiEJ49mV4jME2kttDAV5hwWBoVAUF8yKp80mIgju1lu-q4nI7VsFDM0076; NID=511=efI9IZpxtyJ7Dw1MAUXU8FlzS5jXGewY4Er8HliWc3A0RSWdgvNDyKY66ETjgRyTGWPbWODSmiSeYSBab5SPHVwqbJxd6ZeGW2f6BkHi61UKksXPH0CVJRM1hKpMjHPU5qw7tboM2Mi87NrosV8COB-GCLulLLbjOoSAEQewTe8NVZ5Owq8IkwvxFGfJkmUKEMkFWrw9yb5nTDl3wbZEsGFI92iEdNTSxSRovNCIPN2US-SCFdQ0m2BtvwdiWZbgnn7dSQ8yPA145Kk2BA-ATpJNJ6SJHEHLQY-9CPail9D5qgJgxR925EUg5RGCpEu9wS5xbA62KTa19wAvbAq7Dk3TWc-iX4p1s7ESFyDC7yMpFxiFPJjqkWwFi_ZfiK2TW2t0TQ60DFBxqOytQaLyHrkEvD-CQPVj6OCOP22cZY0Cu61HaAQgFO9pXH-kJUlywzVdbirJumN5gswyaQ49b3KdLcG0Jb7brOMTM24T2nGtQ10hJzsnTwX7dBk3ujqQrI_DGuURvPassPUrIZ0; AEC=Ae3NU9MOEGeKAZjP6INpOYbyMraWAWztmx5pJB_1ILu1furiTy1K37k15u0; __Secure-1PSIDTS=sidts-CjEBYfD7Z9twEKTWJ9gU7KG-rLbxJGNRQIoG3wH6JVu6yiCC2fsRrm7tN8L6d5WlILrnEAA; __Secure-3PSIDTS=sidts-CjEBYfD7Z9twEKTWJ9gU7KG-rLbxJGNRQIoG3wH6JVu6yiCC2fsRrm7tN8L6d5WlILrnEAA; 1P_JAR=2024-02-18-08; SIDCC=ABTWhQExCxkfmwCkG1RaEgz8U1ZkPeh3HmLMUdMt8S5cNSsLY5U5rAL6wlvq7dtjRw7zrtAbqsFI; __Secure-1PSIDCC=ABTWhQH0jLeRIS6Tu3LS8DXB5Q3gGDq9LTmlk60FKu795Bf0UbzsOcYWVAE96clq5aAL8i724Q0; __Secure-3PSIDCC=ABTWhQHIFcyv3nZYwp78WXEQal71jCE_ZsGT5lXs8VLr7XDIfFqHcLTIPz4HxzJb9ZnYQ5l2s9eU\" --header=\"Connection: keep-alive\" \"https://drive.usercontent.google.com/download?id=1lhAaeQCmk2y440PmagA0KmIVBIysVMwu&export=download&authuser=0&confirm=t&uuid=3077628e-fc9b-4ef2-8cde-b291040afb30&at=APZUnTU9lSikCSe3NqbxV5MVad5T%3A1708243355040\" -c -O 'tennis_court_det_dataset.zip'\n","!unzip tennis_court_det_dataset.zip"]},{"cell_type":"code","execution_count":null,"id":"5e93e0d6","metadata":{"id":"5e93e0d6"},"outputs":[],"source":["%pip install torch\n","%pip install torchvision\n","%pip install opencv-python\n","%pip install numpy\n","%pip install coremltools\n","\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import models, transforms\n","\n","import json\n","import cv2\n","import numpy as np\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":null,"id":"f96c6de5","metadata":{"id":"f96c6de5"},"outputs":[],"source":["class KeypointsDataset(Dataset):\n","    def __init__(self, img_dir, data_file):\n","        self.img_dir = img_dir\n","        with open(data_file, \"r\") as f:\n","            self.data = json.load(f)\n","\n","        self.transforms = transforms.Compose([\n","            transforms.ToPILImage(),\n","            transforms.Resize((224, 224)),\n","            transforms.ToTensor(),\n","            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","        ])\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        item = self.data[idx]\n","        img = cv2.imread(f\"{self.img_dir}/{item['id']}.png\")\n","        h,w = img.shape[:2]\n","\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","        img = self.transforms(img)\n","        kps = np.array(item['kps']).flatten()\n","        kps = kps.astype(np.float32)\n","\n","        kps[::2] *= 224.0 / w # Adjust x coordinates\n","        kps[1::2] *= 224.0 / h # Adjust y coordinates\n","\n","        return img, kps\n","\n"]},{"cell_type":"code","execution_count":null,"id":"81118d89","metadata":{"id":"81118d89"},"outputs":[],"source":["train_dataset = KeypointsDataset('data/images', 'data/data_train.json')\n","val_dataset = KeypointsDataset('data/images', 'data/data_val.json')\n","\n","train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=8, shuffle=True)"]},{"cell_type":"code","execution_count":null,"id":"a248e378","metadata":{"id":"a248e378"},"outputs":[],"source":["model = models.resnet50(pretrained=True)\n","model.fc = torch.nn.Linear(model.fc.in_features, 14*2)\n","model = model.to(device)\n","\n","criterion = torch.nn.MSELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"]},{"cell_type":"markdown","id":"b4d2c07a","metadata":{"id":"b4d2c07a"},"source":["## Train the Model, save it\n","Make sure at the end of training we're saving the model weights and architecture properly"]},{"cell_type":"code","execution_count":null,"id":"0fdc1daa","metadata":{"id":"0fdc1daa"},"outputs":[],"source":["epochs = 40\n","for epoch in range(epochs):\n","    model.train()\n","    for i, (img, kps) in enumerate(train_loader):\n","        img = img.to(device)\n","        kps = kps.to(device)\n","\n","        # Flatten keypoints to match model output shape [batch_size, 28]\n","        kps = kps.view(kps.size(0), -1)\n","\n","        optimizer.zero_grad()\n","        outputs = model(img)\n","        loss = criterion(outputs, kps)  # MSELoss between predicted and GT keypoints\n","        loss.backward()\n","        optimizer.step()\n","\n","        if i % 10 == 0:\n","            print(f\"Epoch {epoch}, iter {i}, loss: {loss.item()}\")\n","\n","\n","torch.save(model.state_dict(), 'tennis_keypoint_model_weights.pth')\n"]},{"cell_type":"markdown","id":"2d4c5628","metadata":{"id":"2d4c5628"},"source":["## Convert TorchScript to CoreML .mlpackage\n","Use coreml tools to convert to iOS format for import"]},{"cell_type":"code","execution_count":null,"id":"102cf9b9","metadata":{"id":"102cf9b9"},"outputs":[],"source":["import torch\n","from torchvision import models\n","import torch.nn as nn\n","import coremltools as ct\n","\n","# Rebuild the same model structure\n","model = models.resnet50(pretrained=False)\n","model.fc = nn.Linear(model.fc.in_features, 14 * 2)\n","\n","# Load weights\n","model.load_state_dict(torch.load(\"tennis_keypoint_model_weights.pth\", map_location=\"cpu\"))\n","model.eval()\n","\n","# Prepare dummy input for tracing\n","example_input = torch.rand(1, 3, 224, 224)\n","traced_model = torch.jit.trace(model, example_input)\n","\n","# Convert to CoreML\n","mlmodel = ct.convert(\n","    traced_model,\n","    inputs=[ct.TensorType(shape=example_input.shape)],\n","    convert_to=\"mlprogram\",  # .mlpackage format\n","    minimum_deployment_target=ct.target.iOS15,\n",")\n","\n","# Save CoreML model\n","mlmodel.save(\"keypoints.mlpackage\")\n"]},{"cell_type":"code","execution_count":null,"id":"95df37cd","metadata":{"id":"95df37cd"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","!cp -r keypoints.mlpackage /content/drive/MyDrive/"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"},"colab":{"provenance":[{"file_id":"1wSA1AKKv18j_ydUiMnv1c3w6pK21Zd4Q","timestamp":1754079296876}],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}